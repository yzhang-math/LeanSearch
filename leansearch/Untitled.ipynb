{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2823f812-005f-447e-9ba5-d96ce93f0717",
   "metadata": {},
   "outputs": [
    {
     "ename": "GrammarError",
     "evalue": "Rule 'theorem' used but not defined (in rule statement)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGrammarError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 173\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse Lean code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Test the parser\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m parser \u001b[38;5;241m=\u001b[39m LeanParser()\n\u001b[0;32m    175\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mtheorem add_zero (n : Nat) : n + 0 = n := by\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124m    rfl\u001b[39m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124m    apply nat.zero_add\u001b[39m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124m    simp\u001b[39m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    181\u001b[0m result \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_theorem(code)\n",
      "Cell \u001b[1;32mIn[40], line 157\u001b[0m, in \u001b[0;36mLeanParser.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m Lark(lean_grammar, \n\u001b[0;32m    158\u001b[0m                       parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlalr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    159\u001b[0m                       transformer\u001b[38;5;241m=\u001b[39mLeanTransformer(),\n\u001b[0;32m    160\u001b[0m                       postlex\u001b[38;5;241m=\u001b[39mLeanIndenter(),\n\u001b[0;32m    161\u001b[0m                       debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lark.py:357\u001b[0m, in \u001b[0;36mLark.__init__\u001b[1;34m(self, grammar, **options)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m old_options\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Parse the grammar file and compose the grammars\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar, used_files \u001b[38;5;241m=\u001b[39m load_grammar(grammar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mimport_paths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mkeep_all_tokens)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(grammar, Grammar)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1416\u001b[0m, in \u001b[0;36mload_grammar\u001b[1;34m(grammar, source, import_paths, global_keep_all_tokens)\u001b[0m\n\u001b[0;32m   1414\u001b[0m builder \u001b[38;5;241m=\u001b[39m GrammarBuilder(global_keep_all_tokens, import_paths)\n\u001b[0;32m   1415\u001b[0m builder\u001b[38;5;241m.\u001b[39mload_grammar(grammar, source)\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mbuild(), builder\u001b[38;5;241m.\u001b[39mused_files\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1375\u001b[0m, in \u001b[0;36mGrammarBuilder.build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Grammar:\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[0;32m   1376\u001b[0m     rule_defs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1377\u001b[0m     term_defs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1369\u001b[0m, in \u001b[0;36mGrammarBuilder.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m _find_used_symbols(exp):\n\u001b[0;32m   1368\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sym \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions \u001b[38;5;129;01mand\u001b[39;00m sym \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m-> 1369\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar_error(d\u001b[38;5;241m.\u001b[39mis_term, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{Type}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m used but not defined (in \u001b[39m\u001b[38;5;132;01m{type2}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{name2}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, sym, name)\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_names):\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GrammarError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminals \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m were marked to ignore but were not defined!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_names) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1109\u001b[0m, in \u001b[0;36mGrammarBuilder._grammar_error\u001b[1;34m(self, is_term, msg, *names)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix] \u001b[38;5;241m=\u001b[39m lowercase_type \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal\u001b[39m\u001b[38;5;124m\"\u001b[39m)[is_term]\n\u001b[0;32m   1108\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix] \u001b[38;5;241m=\u001b[39m lowercase_type\u001b[38;5;241m.\u001b[39mtitle()\n\u001b[1;32m-> 1109\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m GrammarError(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs))\n",
      "\u001b[1;31mGrammarError\u001b[0m: Rule 'theorem' used but not defined (in rule statement)"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    OPEN_PAREN_types = ['LPAR']\n",
    "    CLOSE_PAREN_types = ['RPAR']\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    ?start: _NEWLINE* statement _NEWLINE*\n",
    "    ?statement: theorem | definition\n",
    "    \n",
    "    THEOREM: \"theorem\"i \n",
    "    DEF: \"def\"i\n",
    "\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME+ \":\" type\n",
    "\n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "\n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "\n",
    "    proof: \"by\" _NEWLINE _INDENT tactic+ _DEDENT\n",
    "    tactic: qualified_name tactic_arg* _NEWLINE\n",
    "    tactic_arg: qualified_name | STRING | NUMBER | \"(\" term \")\"\n",
    "\n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_']*/\n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\\\r?\\\\n/\n",
    "    WS: /[ \\t]+/\n",
    "\n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "    \n",
    "    def statement(self, items):\n",
    "        return items[0]\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        return \".\".join(str(item) for item in items)\n",
    "    \n",
    "    def param(self, items):\n",
    "        names = items[:-1]  # All but last item are names\n",
    "        type_node = items[-1]  # Last item is the type\n",
    "        return [LeanParam(name=str(name), type=type_node) for name in names]\n",
    "    \n",
    "    def params(self, items):\n",
    "        return [param for params in items for param in params]\n",
    "    \n",
    "    def type(self, items):\n",
    "        name = str(items[0])\n",
    "        params = items[1:] if len(items) > 1 else None\n",
    "        return LeanType(name=name, params=params)\n",
    "    \n",
    "    def term(self, items):\n",
    "        if len(items) == 1:\n",
    "            return str(items[0])\n",
    "        result = []\n",
    "        for i, item in enumerate(items):\n",
    "            result.append(str(item))\n",
    "            if i < len(items) - 1:\n",
    "                result.append(\" \")\n",
    "        return \"\".join(result)\n",
    "    \n",
    "    def term_with_args(self, items):\n",
    "        return \" \".join(str(i) for i in items)\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        # Remove newline from the end if present\n",
    "        if str(items[-1]).strip() == '':\n",
    "            items = items[:-1]\n",
    "        name = str(items[0])\n",
    "        args = [str(arg) for arg in items[1:]] if len(items) > 1 else None\n",
    "        return LeanTactic(name=name, args=args)\n",
    "    \n",
    "    def proof(self, items):\n",
    "        # Filter out non-tactic items and flatten the list\n",
    "        tactics = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                tactics.extend(t for t in item if isinstance(t, LeanTactic))\n",
    "            elif isinstance(item, LeanTactic):\n",
    "                tactics.append(item)\n",
    "        return tactics\n",
    "    \n",
    "    def theorem(self, items):\n",
    "        name = str(items[1])  # Changed from items[0] to items[1] since THEOREM token is now items[0]\n",
    "        current = 2  # Start at 2 since we've used up THEOREM and NAME\n",
    "        \n",
    "        # Handle params if present\n",
    "        params = []\n",
    "        if current < len(items) and isinstance(items[current], list) and all(isinstance(x, LeanParam) for x in items[current]):\n",
    "            params = items[current]\n",
    "            current += 1\n",
    "        \n",
    "        # Handle type\n",
    "        type_term = str(items[current])\n",
    "        current += 1\n",
    "        \n",
    "        # Handle proof if present\n",
    "        proof_tactics = []\n",
    "        if current < len(items):\n",
    "            proof_items = items[current:]\n",
    "            for item in proof_items:\n",
    "                if isinstance(item, list):\n",
    "                    proof_tactics.extend(item)\n",
    "                elif isinstance(item, LeanTactic):\n",
    "                    proof_tactics.append(item)\n",
    "        \n",
    "        return LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)  # Added debug flag\n",
    "    \n",
    "    def parse(self, code: str):\n",
    "        \"\"\"Parse Lean code and return the parsed result\"\"\"\n",
    "        try:\n",
    "            # Add some debug printing\n",
    "            print(f\"Attempting to parse:\\n{code}\")\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error details: {type(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "# Test the parser\n",
    "parser = LeanParser()\n",
    "\n",
    "code = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    apply nat.zero_add\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "result = parser.parse_theorem(code)\n",
    "print(f\"Name: {result.name}\")\n",
    "print(f\"Parameters: {result.params}\")\n",
    "print(f\"Type: {result.type}\")\n",
    "print(\"Proof tactics:\")\n",
    "for tactic in result.proof:\n",
    "    print(f\"  - {tactic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8183de0e-fe27-4252-a75d-609c93959581",
   "metadata": {},
   "outputs": [
    {
     "ename": "GrammarError",
     "evalue": "Rule 'theorem' used but not defined (in rule statement)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGrammarError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m parser \u001b[38;5;241m=\u001b[39m LeanParser()\n\u001b[0;32m      3\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mtheorem add_zero (n : Nat) : n + m = n := by\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    rfl\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      8\u001b[0m result \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_theorem(code)\n",
      "Cell \u001b[1;32mIn[40], line 157\u001b[0m, in \u001b[0;36mLeanParser.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m Lark(lean_grammar, \n\u001b[0;32m    158\u001b[0m                       parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlalr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    159\u001b[0m                       transformer\u001b[38;5;241m=\u001b[39mLeanTransformer(),\n\u001b[0;32m    160\u001b[0m                       postlex\u001b[38;5;241m=\u001b[39mLeanIndenter(),\n\u001b[0;32m    161\u001b[0m                       debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lark.py:357\u001b[0m, in \u001b[0;36mLark.__init__\u001b[1;34m(self, grammar, **options)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m old_options\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Parse the grammar file and compose the grammars\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar, used_files \u001b[38;5;241m=\u001b[39m load_grammar(grammar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mimport_paths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mkeep_all_tokens)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(grammar, Grammar)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1416\u001b[0m, in \u001b[0;36mload_grammar\u001b[1;34m(grammar, source, import_paths, global_keep_all_tokens)\u001b[0m\n\u001b[0;32m   1414\u001b[0m builder \u001b[38;5;241m=\u001b[39m GrammarBuilder(global_keep_all_tokens, import_paths)\n\u001b[0;32m   1415\u001b[0m builder\u001b[38;5;241m.\u001b[39mload_grammar(grammar, source)\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mbuild(), builder\u001b[38;5;241m.\u001b[39mused_files\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1375\u001b[0m, in \u001b[0;36mGrammarBuilder.build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Grammar:\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[0;32m   1376\u001b[0m     rule_defs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1377\u001b[0m     term_defs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1369\u001b[0m, in \u001b[0;36mGrammarBuilder.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m _find_used_symbols(exp):\n\u001b[0;32m   1368\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sym \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions \u001b[38;5;129;01mand\u001b[39;00m sym \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m-> 1369\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar_error(d\u001b[38;5;241m.\u001b[39mis_term, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{Type}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m used but not defined (in \u001b[39m\u001b[38;5;132;01m{type2}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{name2}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, sym, name)\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_names):\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GrammarError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerminals \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m were marked to ignore but were not defined!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_names) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_definitions)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\load_grammar.py:1109\u001b[0m, in \u001b[0;36mGrammarBuilder._grammar_error\u001b[1;34m(self, is_term, msg, *names)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix] \u001b[38;5;241m=\u001b[39m lowercase_type \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal\u001b[39m\u001b[38;5;124m\"\u001b[39m)[is_term]\n\u001b[0;32m   1108\u001b[0m     args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix] \u001b[38;5;241m=\u001b[39m lowercase_type\u001b[38;5;241m.\u001b[39mtitle()\n\u001b[1;32m-> 1109\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m GrammarError(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs))\n",
      "\u001b[1;31mGrammarError\u001b[0m: Rule 'theorem' used but not defined (in rule statement)"
     ]
    }
   ],
   "source": [
    "parser = LeanParser()\n",
    "\n",
    "code = \"\"\"\n",
    "theorem add_zero (n : Nat) : n + m = n := by\n",
    "    rfl\n",
    "\"\"\".strip()\n",
    "\n",
    "result = parser.parse_theorem(code)\n",
    "print(f\"Name: {result.name}\")\n",
    "print(f\"Parameters: {result.params}\")\n",
    "print(f\"Type: {result.type}\")\n",
    "print(f\"Proof tactics: {result.proof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30bb2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "833e6dba-d1d2-4cae-ac47-57b4b4ff1843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Parse error: UnexpectedToken: Unexpected token Token('_DEDENT', '') at line None, column None.\n",
      "Expected one of: \n",
      "\t* NAME\n",
      "\t* _NEWLINE\n",
      "\t* STRING\n",
      "\t* NUMBER\n",
      "\t* LPAR\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to parse Lean code: Unexpected token Token('_DEDENT', '') at line None, column None.\nExpected one of: \n\t* NAME\n\t* _NEWLINE\n\t* STRING\n\t* NUMBER\n\t* LPAR\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser_state.py:77\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[1;34m(self, token, is_end)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     action, arg \u001b[38;5;241m=\u001b[39m states[state][token\u001b[38;5;241m.\u001b[39mtype]\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: '_DEDENT'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnexpectedToken\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 169\u001b[0m, in \u001b[0;36mLeanParser.parse_theorem\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(code)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lark.py:655\u001b[0m, in \u001b[0;36mLark.parse\u001b[1;34m(self, text, start, on_error)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(text, start\u001b[38;5;241m=\u001b[39mstart, on_error\u001b[38;5;241m=\u001b[39mon_error)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parser_frontends.py:104\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[1;34m(self, text, start, on_error)\u001b[0m\n\u001b[0;32m    103\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(stream, chosen_start, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py:42\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[1;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(lexer, start)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py:88\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[1;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_from_state(parser_state)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py:111\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[1;34m(self, state, last_token)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py:102\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[1;34m(self, state, last_token)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     state\u001b[38;5;241m.\u001b[39mfeed_token(token)\n\u001b[0;32m    104\u001b[0m end_token \u001b[38;5;241m=\u001b[39m Token\u001b[38;5;241m.\u001b[39mnew_borrow_pos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, token) \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;28;01melse\u001b[39;00m Token(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$END\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser_state.py:80\u001b[0m, in \u001b[0;36mParserState.feed_token\u001b[1;34m(self, token, is_end)\u001b[0m\n\u001b[0;32m     79\u001b[0m     expected \u001b[38;5;241m=\u001b[39m {s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states[state]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39misupper()}\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, expected, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, interactive_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m arg \u001b[38;5;241m!=\u001b[39m end_state\n",
      "\u001b[1;31mUnexpectedToken\u001b[0m: Unexpected token Token('_DEDENT', '') at line None, column None.\nExpected one of: \n\t* NAME\n\t* _NEWLINE\n\t* STRING\n\t* NUMBER\n\t* LPAR\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mtheorem add_zero (n : Nat) : n + 0 = n := by\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    rfl\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    apply nat.zero_add\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    simp\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_theorem(code)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 172\u001b[0m, in \u001b[0;36mLeanParser.parse_theorem\u001b[1;34m(self, code)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParse error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse Lean code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to parse Lean code: Unexpected token Token('_DEDENT', '') at line None, column None.\nExpected one of: \n\t* NAME\n\t* _NEWLINE\n\t* STRING\n\t* NUMBER\n\t* LPAR\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    apply nat.zero_add\n",
    "    simp\n",
    "\"\"\".strip()\n",
    "\n",
    "result = parser.parse_theorem(code)\n",
    "print(f\"Name: {result.name}\")\n",
    "print(f\"Parameters: {result.params}\")\n",
    "print(f\"Type: {result.type}\")\n",
    "print(f\"Proof tactics: {result.proof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dafdcb9-5cea-4380-b779-795523a9e936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "start\n",
      "  theorem\n",
      "    add_zero\n",
      "    params\n",
      "      param\n",
      "        n\n",
      "        type\tNat\n",
      "    term\tn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark\n",
    "\n",
    "# Minimal grammar to test theorem parsing\n",
    "test_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    type: NAME\n",
    "    term: NAME\n",
    "    proof: \"by\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_']*/\n",
    "    WS: /[ \\t]+/\n",
    "    _NEWLINE: /\\r?\\n/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "\"\"\"\n",
    "\n",
    "parser = Lark(test_grammar, parser='lalr')\n",
    "\n",
    "test_input = \"theorem add_zero (n : Nat) : n\"\n",
    "try:\n",
    "    tree = parser.parse(test_input)\n",
    "    print(\"Success!\")\n",
    "    print(tree.pretty())\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15facf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=None), LeanTactic(name='simp', args=None)]]\n",
      "Parameters in theorem: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=None), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: add_zero\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - apply\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    proof_body: tactic+\n",
    "    tactic: NAME tactic_args? _NEWLINE\n",
    "    tactic_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        \n",
    "        # Get parameters - items[1] should be the list of parameters\n",
    "        params = items[1] if isinstance(items[1], list) else []\n",
    "        print(f\"Parameters in theorem: {params}\")  # Debug print\n",
    "        \n",
    "        type_term = items[2]\n",
    "        proof_tactics = items[3] if len(items) > 3 else []\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        type_val = items[2] if len(items) > 2 else items[1]  # Handle the colon\n",
    "        param = LeanParam(name=name, type=type_val)\n",
    "        print(f\"Created param: {param}\")  # Debug print\n",
    "        return param\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        # Skip parentheses and get only the parameters\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed params: {params}\")  # Debug print\n",
    "        return params\n",
    "\n",
    "    # ... rest of the transformers stay the same ...\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        terms = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                terms.append(item.value)\n",
    "            else:\n",
    "                terms.append(str(item))\n",
    "        return \" \".join(terms)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        return \".\".join(names)\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        return [item for item in items if isinstance(item, LeanTactic)]\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        args = None\n",
    "        if len(items) > 2:  # If we have more than name and newline\n",
    "            args = []\n",
    "            for item in items[1:-1]:  # Skip the last item (newline)\n",
    "                if isinstance(item, Token):\n",
    "                    args.append(item.value)\n",
    "                elif isinstance(item, Tree):\n",
    "                    args.append(str(item.children[0]))\n",
    "                else:\n",
    "                    args.append(str(item))\n",
    "        return LeanTactic(name=name, args=args)\n",
    "    \n",
    "    def proof(self, items):\n",
    "        # Find and return the list of tactics\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    apply nat.zero_add\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cd541c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Tactic items: ['apply', Tree(Token('RULE', 'tactic_args'), ['nat.zero_add'])]\n",
      "Created tactic: LeanTactic(name='apply', args=None)\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=None), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=None), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: add_zero\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - apply\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    proof_body: tactic+\n",
    "    tactic: qualified_name tactic_args? _NEWLINE\n",
    "    tactic_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = items[1] if isinstance(items[1], list) else []\n",
    "        type_term = items[2]\n",
    "        proof_tactics = items[3] if len(items) > 3 else []\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        type_val = items[2] if len(items) > 2 else items[1]\n",
    "        param = LeanParam(name=name, type=type_val)\n",
    "        print(f\"Created param: {param}\")\n",
    "        return param\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed params: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        terms = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                terms.append(item.value)\n",
    "            else:\n",
    "                terms.append(str(item))\n",
    "        return \" \".join(terms)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")  # Debug print\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        return \".\".join(names)\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")  # Debug print\n",
    "        if not items:\n",
    "            return None\n",
    "            \n",
    "        # Get tactic name\n",
    "        if isinstance(items[0], Tree) and items[0].data == 'qualified_name':\n",
    "            name = self.qualified_name(items[0].children)\n",
    "        else:\n",
    "            name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        \n",
    "        # Get arguments\n",
    "        args = []\n",
    "        if len(items) > 2:  # If we have more than name and newline\n",
    "            for item in items[1:-1]:  # Skip the last item (newline)\n",
    "                if isinstance(item, Token):\n",
    "                    args.append(item.value)\n",
    "                elif isinstance(item, Tree):\n",
    "                    if item.data == 'qualified_name':\n",
    "                        args.append(self.qualified_name(item.children))\n",
    "                    else:\n",
    "                        args.append(str(item.children[0]))\n",
    "                else:\n",
    "                    args.append(str(item))\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")  # Debug print\n",
    "        return tactic\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        return [item for item in items if isinstance(item, LeanTactic)]\n",
    "    \n",
    "    def proof(self, items):\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    apply nat.zero_add\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f51278bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Tactic items: ['apply', Tree(Token('RULE', 'tactic_args'), ['nat.zero_add'])]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: add_zero\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - apply nat.zero_add\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    proof_body: tactic+\n",
    "    tactic: qualified_name tactic_args? _NEWLINE\n",
    "    tactic_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = items[1] if isinstance(items[1], list) else []\n",
    "        type_term = items[2]\n",
    "        proof_tactics = items[3] if len(items) > 3 else []\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        type_val = items[2] if len(items) > 2 else items[1]\n",
    "        param = LeanParam(name=name, type=type_val)\n",
    "        print(f\"Created param: {param}\")\n",
    "        return param\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed params: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        terms = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                terms.append(item.value)\n",
    "            else:\n",
    "                terms.append(str(item))\n",
    "        return \" \".join(terms)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        return \".\".join(names)\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        \n",
    "        # Get tactic name from first item\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        \n",
    "        # Process arguments\n",
    "        args = []\n",
    "        for item in items[1:]:  # Look at all items after the name\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'tactic_args':\n",
    "                    # Process each argument in tactic_args\n",
    "                    for arg in item.children:\n",
    "                        if isinstance(arg, Token):\n",
    "                            args.append(arg.value)\n",
    "                        elif isinstance(arg, Tree):\n",
    "                            if arg.data == 'qualified_name':\n",
    "                                args.append(self.qualified_name(arg.children))\n",
    "                            else:\n",
    "                                args.append(str(arg.children[0]))\n",
    "                        else:\n",
    "                            args.append(str(arg))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        return [item for item in items if isinstance(item, LeanTactic)]\n",
    "    \n",
    "    def proof(self, items):\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    apply nat.zero_add\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b7a6bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'repeat')]\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: ['repeat']\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: [Token('NAME', 'try')]\n",
      "Processed qualified name: try\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Plain args items: ['try', 'simp']\n",
      "Processed plain args: ['try', 'simp']\n",
      "Tactic items: ['repeat', ['try', 'simp']]\n",
      "Created tactic: LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Processed qualified name: apply\n",
      "Qualified name items: ['apply']\n",
      "Processed qualified name: apply\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Processed qualified name: nat.zero_add\n",
      "Plain args items: ['nat.zero_add']\n",
      "Processed plain args: ['nat.zero_add']\n",
      "Tactic items: ['apply', ['nat.zero_add']]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'add_comm')]\n",
      "Processed qualified name: add_comm\n",
      "Bracketed names items: ['add_comm']\n",
      "Processed bracketed names: ['add_comm']\n",
      "Bracket args items: [['add_comm']]\n",
      "Processed bracket args: ['add_comm']\n",
      "Tactic items: ['rw', ['add_comm']]\n",
      "Created tactic: LeanTactic(name='rw', args=['add_comm'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'taylorWithinEval_succ')]\n",
      "Processed qualified name: taylorWithinEval_succ\n",
      "Qualified name items: [Token('NAME', 'Finset.sum_range_succ')]\n",
      "Processed qualified name: Finset.sum_range_succ\n",
      "Qualified name items: [Token('NAME', 'hk')]\n",
      "Processed qualified name: hk\n",
      "Bracketed names items: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Processed bracketed names: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Bracket args items: [['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Processed bracket args: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Tactic items: ['rw', ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Created tactic: LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: add_zero\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - repeat try simp\n",
      "  - apply nat.zero_add\n",
      "  - rw add_comm\n",
      "  - rw taylorWithinEval_succ Finset.sum_range_succ hk\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    proof_body: tactic+\n",
    "    tactic: tactic_name tactic_args? _NEWLINE\n",
    "    tactic_name: qualified_name\n",
    "    \n",
    "    ?tactic_args: bracket_args | plain_args\n",
    "    plain_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    bracket_args: \"[\" bracketed_names \"]\"\n",
    "    bracketed_names: qualified_name (\",\" qualified_name)*\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = items[1] if isinstance(items[1], list) else []\n",
    "        type_term = items[2]\n",
    "        proof_tactics = items[3] if len(items) > 3 else []\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        type_val = items[2] if len(items) > 2 else items[1]\n",
    "        param = LeanParam(name=name, type=type_val)\n",
    "        print(f\"Created param: {param}\")\n",
    "        return param\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed params: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        return \" \".join(str(item) for item in items)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        result = \".\".join(names)\n",
    "        print(f\"Processed qualified name: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def tactic_name(self, items):\n",
    "        return self.qualified_name(items)\n",
    "    \n",
    "    def plain_args(self, items):\n",
    "        print(f\"Plain args items: {items}\")\n",
    "        args = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                args.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                if item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "                else:\n",
    "                    args.append(str(item.children[0]))\n",
    "            else:\n",
    "                args.append(str(item))\n",
    "        print(f\"Processed plain args: {args}\")\n",
    "        return args\n",
    "    \n",
    "    def bracketed_names(self, items):\n",
    "        print(f\"Bracketed names items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'qualified_name':\n",
    "                names.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token):\n",
    "                if item.type not in {'COMMA', 'LSQB', 'RSQB'}:\n",
    "                    names.append(item.value)\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "        print(f\"Processed bracketed names: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def bracket_args(self, items):\n",
    "        print(f\"Bracket args items: {items}\")\n",
    "        # Find the bracketed_names in the items\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'bracketed_names':\n",
    "                result = self.visit(item)\n",
    "                print(f\"Processed bracket args: {result}\")\n",
    "                return result\n",
    "            elif isinstance(item, list):\n",
    "                print(f\"Processed bracket args: {item}\")\n",
    "                return item\n",
    "        print(\"No valid bracket args found\")\n",
    "        return []\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        \n",
    "        # Get tactic name\n",
    "        name = items[0]\n",
    "        \n",
    "        # Process arguments\n",
    "        args = []\n",
    "        for item in items[1:]:  # Look at all items after the name\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'bracket_args':\n",
    "                    # Handle bracket args directly\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'plain_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, list):\n",
    "                args.extend(item)\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        return [item for item in items if isinstance(item, LeanTactic)]\n",
    "    \n",
    "    def proof(self, items):\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    rw [taylorWithinEval_succ, Finset.sum_range_succ, hk]\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3f3aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [Token('NAME', 'n'), LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Params items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed params: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'repeat')]\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: ['repeat']\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: [Token('NAME', 'try')]\n",
      "Processed qualified name: try\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Plain args items: ['try', 'simp']\n",
      "Processed plain args: ['try', 'simp']\n",
      "Tactic items: ['repeat', ['try', 'simp']]\n",
      "Created tactic: LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Processed qualified name: apply\n",
      "Qualified name items: ['apply']\n",
      "Processed qualified name: apply\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Processed qualified name: nat.zero_add\n",
      "Plain args items: ['nat.zero_add']\n",
      "Processed plain args: ['nat.zero_add']\n",
      "Tactic items: ['apply', ['nat.zero_add']]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'add_comm')]\n",
      "Processed qualified name: add_comm\n",
      "Bracketed names items: ['add_comm']\n",
      "Processed bracketed names: ['add_comm']\n",
      "Bracket args items: [['add_comm']]\n",
      "Processed bracket args: ['add_comm']\n",
      "Tactic items: ['rw', ['add_comm']]\n",
      "Created tactic: LeanTactic(name='rw', args=['add_comm'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'taylorWithinEval_succ')]\n",
      "Processed qualified name: taylorWithinEval_succ\n",
      "Qualified name items: [Token('NAME', 'Finset.sum_range_succ')]\n",
      "Processed qualified name: Finset.sum_range_succ\n",
      "Qualified name items: [Token('NAME', 'hk')]\n",
      "Processed qualified name: hk\n",
      "Bracketed names items: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Processed bracketed names: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Bracket args items: [['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Processed bracket args: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Tactic items: ['rw', ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Created tactic: LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='repeat', args=['try', 'simp']), Token('_NEWLINE', '\\n    '), LeanTactic(name='apply', args=['nat.zero_add']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['add_comm']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None), Token('_NEWLINE', '\\n')]\n",
      "Processed proof body: [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]\n",
      "Proof items: [[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: add_zero\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - repeat try simp\n",
      "  - apply nat.zero_add\n",
      "  - rw add_comm\n",
      "  - rw taylorWithinEval_succ Finset.sum_range_succ hk\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param (\",\" param)* \")\"\n",
    "    param: NAME \":\" type\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    !proof_body: (tactic _NEWLINE*)* -> proof_body\n",
    "    tactic: tactic_name tactic_args?\n",
    "    tactic_name: qualified_name\n",
    "    \n",
    "    ?tactic_args: bracket_args | plain_args\n",
    "    plain_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    bracket_args: \"[\" bracketed_names \"]\"\n",
    "    bracketed_names: qualified_name (\",\" qualified_name)*\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = items[1] if isinstance(items[1], list) else []\n",
    "        type_term = items[2]\n",
    "        proof_tactics = items[3] if len(items) > 3 else []\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        type_val = items[2] if len(items) > 2 else items[1]\n",
    "        param = LeanParam(name=name, type=type_val)\n",
    "        print(f\"Created param: {param}\")\n",
    "        return param\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed params: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        return \" \".join(str(item) for item in items)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        result = \".\".join(names)\n",
    "        print(f\"Processed qualified name: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def tactic_name(self, items):\n",
    "        return self.qualified_name(items)\n",
    "    \n",
    "    def plain_args(self, items):\n",
    "        print(f\"Plain args items: {items}\")\n",
    "        args = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                args.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                if item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "                else:\n",
    "                    args.append(str(item.children[0]))\n",
    "            else:\n",
    "                args.append(str(item))\n",
    "        print(f\"Processed plain args: {args}\")\n",
    "        return args\n",
    "    \n",
    "    def bracketed_names(self, items):\n",
    "        print(f\"Bracketed names items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'qualified_name':\n",
    "                names.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token):\n",
    "                if item.type not in {'COMMA', 'LSQB', 'RSQB'}:\n",
    "                    names.append(item.value)\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "        print(f\"Processed bracketed names: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def bracket_args(self, items):\n",
    "        print(f\"Bracket args items: {items}\")\n",
    "        # Find the bracketed_names in the items\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'bracketed_names':\n",
    "                result = self.visit(item)\n",
    "                print(f\"Processed bracket args: {result}\")\n",
    "                return result\n",
    "            elif isinstance(item, list):\n",
    "                print(f\"Processed bracket args: {item}\")\n",
    "                return item\n",
    "        print(\"No valid bracket args found\")\n",
    "        return []\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        print(f\"Proof body items: {items}\")\n",
    "        tactics = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanTactic):\n",
    "                tactics.append(item)\n",
    "            elif isinstance(item, Tree) and item.data == 'tactic':\n",
    "                tactics.append(self.visit(item))\n",
    "        print(f\"Processed proof body: {tactics}\")\n",
    "        return tactics\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        \n",
    "        # Get tactic name\n",
    "        name = items[0]\n",
    "        \n",
    "        # Process arguments\n",
    "        args = []\n",
    "        for item in items[1:]:  # Look at all items after the name\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'bracket_args':\n",
    "                    # Handle bracket args directly\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'plain_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, list):\n",
    "                args.extend(item)\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof(self, items):\n",
    "        print(f\"Proof items: {items}\")\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "            elif isinstance(item, Tree) and item.data == 'proof_body':\n",
    "                return self.visit(item)\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    rw [taylorWithinEval_succ, Finset.sum_range_succ, hk]\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "235d9593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name list items: [Token('NAME', 'p'), Token('NAME', 'q'), Token('NAME', 'r')]\n",
      "Processed name list: ['p', 'q', 'r']\n",
      "Type items: [Token('NAME', 'Prop')]\n",
      "Param items: [['p', 'q', 'r'], LeanType(name='Prop', params=None)]\n",
      "Created param: LeanParam(name='p', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='q', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='r', type=LeanType(name='Prop', params=None))\n",
      "Param list items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Processed param list: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]\n",
      "Parse error: UnexpectedToken: Unexpected token Token('LPAR', '(') at line 1, column 31.\n",
      "Expected one of: \n",
      "\t* COLON\n",
      "Previous tokens: [Token('RPAR', ')')]\n",
      "\n",
      "Error: Failed to parse Lean code: Unexpected token Token('LPAR', '(') at line 1, column 31.\n",
      "Expected one of: \n",
      "\t* COLON\n",
      "Previous tokens: [Token('RPAR', ')')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lexer.py\", line 665, in lex\n",
      "    yield lexer.next_token(lexer_state, parser_state)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lexer.py\", line 598, in next_token\n",
      "    raise UnexpectedCharacters(lex_state.text, line_ctr.char_pos, line_ctr.line, line_ctr.column,\n",
      "lark.exceptions.UnexpectedCharacters: No terminal matches '(' in the current parser context, at line 1 col 31\n",
      "\n",
      "theorem th_name (p q r : Prop)(a b c : Nat) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ \n",
      "                              ^\n",
      "Expected one of: \n",
      "\t* _NEWLINE\n",
      "\t* COLON\n",
      "\n",
      "Previous tokens: Token('RPAR', ')')\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\2608087440.py\", line 276, in parse_theorem\n",
      "    return self.parser.parse(code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lark.py\", line 655, in parse\n",
      "    return self.parser.parse(text, start=start, on_error=on_error)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parser_frontends.py\", line 104, in parse\n",
      "    return self.parser.parse(stream, chosen_start, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 42, in parse\n",
      "    return self.parser.parse(lexer, start)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 88, in parse\n",
      "    return self.parse_from_state(parser_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 111, in parse_from_state\n",
      "    raise e\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 100, in parse_from_state\n",
      "    for token in state.lexer.lex(state):\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\indenter.py\", line 58, in _process\n",
      "    for token in stream:\n",
      "                 ^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lexer.py\", line 674, in lex\n",
      "    raise UnexpectedToken(token, e.allowed, state=parser_state, token_history=[last_token], terminals_by_name=self.root_lexer.terminals_by_name)\n",
      "lark.exceptions.UnexpectedToken: Unexpected token Token('LPAR', '(') at line 1, column 31.\n",
      "Expected one of: \n",
      "\t* COLON\n",
      "Previous tokens: [Token('RPAR', ')')]\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\2608087440.py\", line 293, in <module>\n",
      "    result = parser.parse_theorem(test_input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\2608087440.py\", line 279, in parse_theorem\n",
      "    raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
      "ValueError: Failed to parse Lean code: Unexpected token Token('LPAR', '(') at line 1, column 31.\n",
      "Expected one of: \n",
      "\t* COLON\n",
      "Previous tokens: [Token('RPAR', ')')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME params? \":\" term (\":=\" proof)?\n",
    "    params: \"(\" param_list \")\"\n",
    "    param_list: param (\",\" param)*\n",
    "    param: name_list \":\" type\n",
    "    name_list: NAME (WS? NAME)*\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    !proof_body: (tactic _NEWLINE*)* -> proof_body\n",
    "    tactic: tactic_name tactic_args?\n",
    "    tactic_name: qualified_name\n",
    "    \n",
    "    ?tactic_args: bracket_args | plain_args\n",
    "    plain_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    bracket_args: \"[\" bracketed_names \"]\"\n",
    "    bracketed_names: qualified_name (\",\" qualified_name)*\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = []\n",
    "        type_term = None\n",
    "        proof_tactics = []\n",
    "        \n",
    "        for item in items[1:]:\n",
    "            if isinstance(item, Tree) and item.data == 'params':\n",
    "                # Extract params from the Tree\n",
    "                params = self.visit(item)\n",
    "            elif isinstance(item, list):\n",
    "                if all(isinstance(x, LeanTactic) for x in item):\n",
    "                    proof_tactics = item\n",
    "                elif all(isinstance(x, LeanParam) for x in item):\n",
    "                    params = item\n",
    "            else:\n",
    "                type_term = str(item)\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        # items[0] will be the param_list result\n",
    "        return items[0]\n",
    "    \n",
    "    def param_list(self, items):\n",
    "        print(f\"Param list items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                params.extend(item)\n",
    "            elif isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed param list: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def name_list(self, items):\n",
    "        print(f\"Name list items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token) and item.type == 'NAME':\n",
    "                names.append(item.value)\n",
    "        print(f\"Processed name list: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        # First item is now a list of names from name_list\n",
    "        names = items[0] if isinstance(items[0], list) else [items[0]]\n",
    "        type_val = None\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanType):\n",
    "                type_val = item\n",
    "        \n",
    "        params = []\n",
    "        for name in names:\n",
    "            param = LeanParam(name=name, type=type_val)\n",
    "            print(f\"Created param: {param}\")\n",
    "            params.append(param)\n",
    "        \n",
    "        return params[0] if len(params) == 1 else params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        return \" \".join(str(item) for item in items)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        result = \".\".join(names)\n",
    "        print(f\"Processed qualified name: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def tactic_name(self, items):\n",
    "        return self.qualified_name(items)\n",
    "    \n",
    "    def plain_args(self, items):\n",
    "        print(f\"Plain args items: {items}\")\n",
    "        args = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                args.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                if item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "                else:\n",
    "                    args.append(str(item.children[0]))\n",
    "            else:\n",
    "                args.append(str(item))\n",
    "        print(f\"Processed plain args: {args}\")\n",
    "        return args\n",
    "    \n",
    "    def bracketed_names(self, items):\n",
    "        print(f\"Bracketed names items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'qualified_name':\n",
    "                names.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token):\n",
    "                if item.type not in {'COMMA', 'LSQB', 'RSQB'}:\n",
    "                    names.append(item.value)\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "        print(f\"Processed bracketed names: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def bracket_args(self, items):\n",
    "        print(f\"Bracket args items: {items}\")\n",
    "        # Find the bracketed_names in the items\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'bracketed_names':\n",
    "                result = self.visit(item)\n",
    "                print(f\"Processed bracket args: {result}\")\n",
    "                return result\n",
    "            elif isinstance(item, list):\n",
    "                print(f\"Processed bracket args: {item}\")\n",
    "                return item\n",
    "        print(\"No valid bracket args found\")\n",
    "        return []\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        print(f\"Proof body items: {items}\")\n",
    "        tactics = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanTactic):\n",
    "                tactics.append(item)\n",
    "            elif isinstance(item, Tree) and item.data == 'tactic':\n",
    "                tactics.append(self.visit(item))\n",
    "        print(f\"Processed proof body: {tactics}\")\n",
    "        return tactics\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        \n",
    "        # Get tactic name\n",
    "        name = items[0]\n",
    "        \n",
    "        # Process arguments\n",
    "        args = []\n",
    "        for item in items[1:]:  # Look at all items after the name\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'bracket_args':\n",
    "                    # Handle bracket args directly\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'plain_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, list):\n",
    "                args.extend(item)\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof(self, items):\n",
    "        print(f\"Proof items: {items}\")\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "            elif isinstance(item, Tree) and item.data == 'proof_body':\n",
    "                return self.visit(item)\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem th_name (p q r : Prop)(a b c : Nat) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    rw [taylorWithinEval_succ, Finset.sum_range_succ, hk]\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66e4a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name list items: [Token('NAME', 'p'), Token('NAME', 'q'), Token('NAME', 'r')]\n",
      "Processed name list: ['p', 'q', 'r']\n",
      "Type items: [Token('NAME', 'Prop')]\n",
      "Param items: [['p', 'q', 'r'], LeanType(name='Prop', params=None)]\n",
      "Created param: LeanParam(name='p', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='q', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='r', type=LeanType(name='Prop', params=None))\n",
      "Param list items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Processed param list: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]\n",
      "Params items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Name list items: [Token('NAME', 'a'), Token('NAME', 'b'), Token('NAME', 'c')]\n",
      "Processed name list: ['a', 'b', 'c']\n",
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [['a', 'b', 'c'], LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='a', type=LeanType(name='Nat', params=None))\n",
      "Created param: LeanParam(name='b', type=LeanType(name='Nat', params=None))\n",
      "Created param: LeanParam(name='c', type=LeanType(name='Nat', params=None))\n",
      "Param list items: [[LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param list: [LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]\n",
      "Params items: [[LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Param groups items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))], [LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param groups: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'repeat')]\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: ['repeat']\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: [Token('NAME', 'try')]\n",
      "Processed qualified name: try\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Plain args items: ['try', 'simp']\n",
      "Processed plain args: ['try', 'simp']\n",
      "Tactic items: ['repeat', ['try', 'simp']]\n",
      "Created tactic: LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Processed qualified name: apply\n",
      "Qualified name items: ['apply']\n",
      "Processed qualified name: apply\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Processed qualified name: nat.zero_add\n",
      "Plain args items: ['nat.zero_add']\n",
      "Processed plain args: ['nat.zero_add']\n",
      "Tactic items: ['apply', ['nat.zero_add']]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'add_comm')]\n",
      "Processed qualified name: add_comm\n",
      "Bracketed names items: ['add_comm']\n",
      "Processed bracketed names: ['add_comm']\n",
      "Bracket args items: [['add_comm']]\n",
      "Processed bracket args: ['add_comm']\n",
      "Tactic items: ['rw', ['add_comm']]\n",
      "Created tactic: LeanTactic(name='rw', args=['add_comm'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'taylorWithinEval_succ')]\n",
      "Processed qualified name: taylorWithinEval_succ\n",
      "Qualified name items: [Token('NAME', 'Finset.sum_range_succ')]\n",
      "Processed qualified name: Finset.sum_range_succ\n",
      "Qualified name items: [Token('NAME', 'hk')]\n",
      "Processed qualified name: hk\n",
      "Bracketed names items: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Processed bracketed names: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Bracket args items: [['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Processed bracket args: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Tactic items: ['rw', ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Created tactic: LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='repeat', args=['try', 'simp']), Token('_NEWLINE', '\\n    '), LeanTactic(name='apply', args=['nat.zero_add']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['add_comm']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None), Token('_NEWLINE', '\\n')]\n",
      "Processed proof body: [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]\n",
      "Proof items: [[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Theorem items: [Token('NAME', 'th_name'), [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))], 'p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r', [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='th_name', params=[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))], type='p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful!\n",
      "Name: th_name\n",
      "Parameters: ['p: Prop', 'q: Prop', 'r: Prop', 'a: Nat', 'b: Nat', 'c: Nat']\n",
      "Type: p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - repeat try simp\n",
      "  - apply nat.zero_add\n",
      "  - rw add_comm\n",
      "  - rw taylorWithinEval_succ Finset.sum_range_succ hk\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME param_groups? \":\" term (\":=\" proof)?\n",
    "    param_groups: params+\n",
    "    params: \"(\" param_list \")\"\n",
    "    param_list: param (\",\" param)*\n",
    "    param: name_list \":\" type\n",
    "    name_list: NAME (WS? NAME)*\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    !proof_body: (tactic _NEWLINE*)* -> proof_body\n",
    "    tactic: tactic_name tactic_args?\n",
    "    tactic_name: qualified_name\n",
    "    \n",
    "    ?tactic_args: bracket_args | plain_args\n",
    "    plain_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    bracket_args: \"[\" bracketed_names \"]\"\n",
    "    bracketed_names: qualified_name (\",\" qualified_name)*\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = []\n",
    "        type_term = None\n",
    "        proof_tactics = []\n",
    "        \n",
    "        for item in items[1:]:\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'param_groups':\n",
    "                    params = self.visit(item)\n",
    "            elif isinstance(item, list):\n",
    "                if all(isinstance(x, LeanTactic) for x in item):\n",
    "                    proof_tactics = item\n",
    "                elif all(isinstance(x, LeanParam) for x in item):\n",
    "                    params = item\n",
    "            else:\n",
    "                type_term = str(item)\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param_groups(self, items):\n",
    "        print(f\"Param groups items: {items}\")\n",
    "        all_params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                all_params.extend(item)\n",
    "            elif isinstance(item, LeanParam):\n",
    "                all_params.append(item)\n",
    "        print(f\"Processed param groups: {all_params}\")\n",
    "        return all_params\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        # items[0] will be the param_list result\n",
    "        return items[0]\n",
    "    \n",
    "    def param_list(self, items):\n",
    "        print(f\"Param list items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                params.extend(item)\n",
    "            elif isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed param list: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def name_list(self, items):\n",
    "        print(f\"Name list items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token) and item.type == 'NAME':\n",
    "                names.append(item.value)\n",
    "        print(f\"Processed name list: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        # First item is now a list of names from name_list\n",
    "        names = items[0] if isinstance(items[0], list) else [items[0]]\n",
    "        type_val = None\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanType):\n",
    "                type_val = item\n",
    "        \n",
    "        params = []\n",
    "        for name in names:\n",
    "            param = LeanParam(name=name, type=type_val)\n",
    "            print(f\"Created param: {param}\")\n",
    "            params.append(param)\n",
    "        \n",
    "        return params[0] if len(params) == 1 else params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        return \" \".join(str(item) for item in items)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        result = \".\".join(names)\n",
    "        print(f\"Processed qualified name: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def tactic_name(self, items):\n",
    "        return self.qualified_name(items)\n",
    "    \n",
    "    def plain_args(self, items):\n",
    "        print(f\"Plain args items: {items}\")\n",
    "        args = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                args.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                if item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "                else:\n",
    "                    args.append(str(item.children[0]))\n",
    "            else:\n",
    "                args.append(str(item))\n",
    "        print(f\"Processed plain args: {args}\")\n",
    "        return args\n",
    "    \n",
    "    def bracketed_names(self, items):\n",
    "        print(f\"Bracketed names items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'qualified_name':\n",
    "                names.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token):\n",
    "                if item.type not in {'COMMA', 'LSQB', 'RSQB'}:\n",
    "                    names.append(item.value)\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "        print(f\"Processed bracketed names: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def bracket_args(self, items):\n",
    "        print(f\"Bracket args items: {items}\")\n",
    "        # Find the bracketed_names in the items\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'bracketed_names':\n",
    "                result = self.visit(item)\n",
    "                print(f\"Processed bracket args: {result}\")\n",
    "                return result\n",
    "            elif isinstance(item, list):\n",
    "                print(f\"Processed bracket args: {item}\")\n",
    "                return item\n",
    "        print(\"No valid bracket args found\")\n",
    "        return []\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        print(f\"Proof body items: {items}\")\n",
    "        tactics = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanTactic):\n",
    "                tactics.append(item)\n",
    "            elif isinstance(item, Tree) and item.data == 'tactic':\n",
    "                tactics.append(self.visit(item))\n",
    "        print(f\"Processed proof body: {tactics}\")\n",
    "        return tactics\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        \n",
    "        # Get tactic name\n",
    "        name = items[0]\n",
    "        \n",
    "        # Process arguments\n",
    "        args = []\n",
    "        for item in items[1:]:  # Look at all items after the name\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'bracket_args':\n",
    "                    # Handle bracket args directly\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'plain_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, list):\n",
    "                args.extend(item)\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof(self, items):\n",
    "        print(f\"Proof items: {items}\")\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "            elif isinstance(item, Tree) and item.data == 'proof_body':\n",
    "                return self.visit(item)\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"theorem th_name (p q r : Prop)(a b c : Nat) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    rw [taylorWithinEval_succ, Finset.sum_range_succ, hk]\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 97,
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
   "id": "615fb830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name list items: [Token('NAME', 'n')]\n",
      "Processed name list: ['n']\n",
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [['n'], LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Param list items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed param list: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Params items: [[LeanParam(name='n', type=LeanType(name='Nat', params=None))]]\n",
      "Param groups items: [[LeanParam(name='n', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param groups: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None), Token('_NEWLINE', '\\n')]\n",
      "Processed proof body: [LeanTactic(name='rfl', args=None), LeanTactic(name='simp', args=None)]\n",
      "Proof items: [[LeanTactic(name='rfl', args=None), LeanTactic(name='simp', args=None)]]\n",
      "Theorem items: [Token('NAME', 'first'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='first', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='simp', args=None)])\n",
      "Name list items: [Token('NAME', 'p'), Token('NAME', 'q'), Token('NAME', 'r')]\n",
      "Processed name list: ['p', 'q', 'r']\n",
      "Type items: [Token('NAME', 'Prop')]\n",
      "Param items: [['p', 'q', 'r'], LeanType(name='Prop', params=None)]\n",
      "Created param: LeanParam(name='p', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='q', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='r', type=LeanType(name='Prop', params=None))\n",
      "Param list items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Processed param list: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]\n",
      "Params items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Name list items: [Token('NAME', 'a'), Token('NAME', 'b'), Token('NAME', 'c')]\n",
      "Processed name list: ['a', 'b', 'c']\n",
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [['a', 'b', 'c'], LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='a', type=LeanType(name='Nat', params=None))\n",
      "Created param: LeanParam(name='b', type=LeanType(name='Nat', params=None))\n",
      "Created param: LeanParam(name='c', type=LeanType(name='Nat', params=None))\n",
      "Param list items: [[LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param list: [LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]\n",
      "Params items: [[LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Param groups items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))], [LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param groups: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'repeat')]\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: ['repeat']\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: [Token('NAME', 'try')]\n",
      "Processed qualified name: try\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Plain args items: ['try', 'simp']\n",
      "Processed plain args: ['try', 'simp']\n",
      "Tactic items: ['repeat', ['try', 'simp']]\n",
      "Created tactic: LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Processed qualified name: apply\n",
      "Qualified name items: ['apply']\n",
      "Processed qualified name: apply\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Processed qualified name: nat.zero_add\n",
      "Plain args items: ['nat.zero_add']\n",
      "Processed plain args: ['nat.zero_add']\n",
      "Tactic items: ['apply', ['nat.zero_add']]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'add_comm')]\n",
      "Processed qualified name: add_comm\n",
      "Bracketed names items: ['add_comm']\n",
      "Processed bracketed names: ['add_comm']\n",
      "Bracket args items: [['add_comm']]\n",
      "Processed bracket args: ['add_comm']\n",
      "Tactic items: ['rw', ['add_comm']]\n",
      "Created tactic: LeanTactic(name='rw', args=['add_comm'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='repeat', args=['try', 'simp']), Token('_NEWLINE', '\\n    '), LeanTactic(name='apply', args=['nat.zero_add']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['add_comm']), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None), Token('_NEWLINE', '\\n')]\n",
      "Processed proof body: [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='simp', args=None)]\n",
      "Proof items: [[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='simp', args=None)]]\n",
      "Theorem items: [Token('NAME', 'second'), [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))], 'p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r', [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='second', params=[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None)), LeanParam(name='a', type=LeanType(name='Nat', params=None)), LeanParam(name='b', type=LeanType(name='Nat', params=None)), LeanParam(name='c', type=LeanType(name='Nat', params=None))], type='p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='simp', args=None)])\n",
      "\n",
      "Parsing successful! Found 2 theorems:\n",
      "\n",
      "Theorem: first\n",
      "Parameters: ['n: Nat']\n",
      "Type: n + 0 = n\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - simp\n",
      "\n",
      "Theorem: second\n",
      "Parameters: ['p: Prop', 'q: Prop', 'r: Prop', 'a: Nat', 'b: Nat', 'c: Nat']\n",
      "Type: p ∧ q ∨ r ↔ p ∧ q ∨ p ∧ r\n",
      "Proof tactics:\n",
      "  - rfl\n",
      "  - repeat try simp\n",
      "  - apply nat.zero_add\n",
      "  - rw add_comm\n",
      "  - simp\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark, Transformer, Tree, Token\n",
    "from lark.indenter import Indenter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class LeanTactic:\n",
    "    name: str\n",
    "    args: List[str] = None\n",
    "\n",
    "@dataclass\n",
    "class LeanType:\n",
    "    name: str\n",
    "    params: List['LeanType'] = None\n",
    "    \n",
    "@dataclass\n",
    "class LeanParam:\n",
    "    name: str\n",
    "    type: LeanType\n",
    "\n",
    "@dataclass\n",
    "class LeanTheorem:\n",
    "    name: str\n",
    "    params: List[LeanParam]\n",
    "    type: str\n",
    "    proof: List[LeanTactic]\n",
    "\n",
    "class LeanIndenter(Indenter):\n",
    "    NL_type = '_NEWLINE'\n",
    "    INDENT_type = '_INDENT'\n",
    "    DEDENT_type = '_DEDENT'\n",
    "    OPEN_PAREN_types = ['LPAR', '\"(\"']\n",
    "    CLOSE_PAREN_types = ['RPAR', '\")\"']\n",
    "    tab_len = 4\n",
    "\n",
    "lean_grammar = r\"\"\"\n",
    "    start: theorem\n",
    "    \n",
    "    theorem: \"theorem\" NAME param_groups? \":\" term (\":=\" proof)?\n",
    "    param_groups: params+\n",
    "    params: \"(\" param_list \")\"\n",
    "    param_list: param (\",\" param)*\n",
    "    param: name_list \":\" type\n",
    "    name_list: NAME (WS? NAME)*\n",
    "    \n",
    "    type: NAME (\"<\" type (\",\" type)* \">\")?\n",
    "    \n",
    "    term: simple_term (OPERATOR simple_term)*\n",
    "    ?simple_term: qualified_name | STRING | NUMBER | term_with_args | \"(\" term \")\"\n",
    "    term_with_args: qualified_name simple_term+\n",
    "    qualified_name: NAME (\".\" NAME)*\n",
    "    \n",
    "    proof: \"by\" _NEWLINE _INDENT proof_body _DEDENT\n",
    "    !proof_body: (tactic _NEWLINE*)* -> proof_body\n",
    "    tactic: tactic_name tactic_args?\n",
    "    tactic_name: qualified_name\n",
    "    \n",
    "    ?tactic_args: bracket_args | plain_args\n",
    "    plain_args: (qualified_name | STRING | NUMBER | \"(\" term \")\")+\n",
    "    \n",
    "    bracket_args: \"[\" bracketed_names \"]\"\n",
    "    bracketed_names: qualified_name (\",\" qualified_name)*\n",
    "    \n",
    "    OPERATOR: \"+\" | \"-\" | \"*\" | \"/\" | \"=\" | \"≠\" | \"≤\" | \"≥\" | \"<\" | \">\" | \"∧\" | \"∨\" | \"→\" | \"↔\" | \"∈\" | \"∉\" | \"⊆\" | \"⊂\" | \"∪\" | \"∩\"\n",
    "    NAME: /[a-zA-Z_][a-zA-Z0-9_'.]*/ \n",
    "    NUMBER: /[0-9]+/\n",
    "    STRING: /\\\"[^\\\"]*\\\"/\n",
    "    _NEWLINE: /\\r?\\n[\\t ]*/\n",
    "    WS: /[ \\t]+/\n",
    "    \n",
    "    %import common.WS_INLINE\n",
    "    %ignore WS_INLINE\n",
    "    %ignore WS\n",
    "    %declare _INDENT _DEDENT\n",
    "\"\"\"\n",
    "\n",
    "class LeanTransformer(Transformer):\n",
    "    def start(self, items):\n",
    "        return items[0]\n",
    "\n",
    "    def theorem(self, items):\n",
    "        print(f\"Theorem items: {items}\")\n",
    "        name = items[0].value\n",
    "        params = []\n",
    "        type_term = None\n",
    "        proof_tactics = []\n",
    "        \n",
    "        for item in items[1:]:\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'param_groups':\n",
    "                    params = self.visit(item)\n",
    "            elif isinstance(item, list):\n",
    "                if all(isinstance(x, LeanTactic) for x in item):\n",
    "                    proof_tactics = item\n",
    "                elif all(isinstance(x, LeanParam) for x in item):\n",
    "                    params = item\n",
    "            else:\n",
    "                type_term = str(item)\n",
    "        \n",
    "        theorem = LeanTheorem(\n",
    "            name=name,\n",
    "            params=params,\n",
    "            type=type_term,\n",
    "            proof=proof_tactics\n",
    "        )\n",
    "        print(f\"Created theorem object: {theorem}\")\n",
    "        return theorem\n",
    "    \n",
    "    def param_groups(self, items):\n",
    "        print(f\"Param groups items: {items}\")\n",
    "        all_params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                all_params.extend(item)\n",
    "            elif isinstance(item, LeanParam):\n",
    "                all_params.append(item)\n",
    "        print(f\"Processed param groups: {all_params}\")\n",
    "        return all_params\n",
    "    \n",
    "    def params(self, items):\n",
    "        print(f\"Params items: {items}\")\n",
    "        return items[0]\n",
    "    \n",
    "    def param_list(self, items):\n",
    "        print(f\"Param list items: {items}\")\n",
    "        params = []\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                params.extend(item)\n",
    "            elif isinstance(item, LeanParam):\n",
    "                params.append(item)\n",
    "        print(f\"Processed param list: {params}\")\n",
    "        return params\n",
    "    \n",
    "    def name_list(self, items):\n",
    "        print(f\"Name list items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token) and item.type == 'NAME':\n",
    "                names.append(item.value)\n",
    "        print(f\"Processed name list: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def param(self, items):\n",
    "        print(f\"Param items: {items}\")\n",
    "        names = items[0] if isinstance(items[0], list) else [items[0]]\n",
    "        type_val = None\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanType):\n",
    "                type_val = item\n",
    "        \n",
    "        params = []\n",
    "        for name in names:\n",
    "            param = LeanParam(name=name, type=type_val)\n",
    "            print(f\"Created param: {param}\")\n",
    "            params.append(param)\n",
    "        \n",
    "        return params[0] if len(params) == 1 else params\n",
    "    \n",
    "    def type(self, items):\n",
    "        print(f\"Type items: {items}\")\n",
    "        name = items[0].value if isinstance(items[0], Token) else str(items[0])\n",
    "        return LeanType(name=name)\n",
    "    \n",
    "    def term(self, items):\n",
    "        return \" \".join(str(item) for item in items)\n",
    "    \n",
    "    def qualified_name(self, items):\n",
    "        print(f\"Qualified name items: {items}\")\n",
    "        if isinstance(items, str):\n",
    "            return items\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                names.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                names.extend(self.qualified_name(item.children))\n",
    "            else:\n",
    "                names.append(str(item))\n",
    "        result = \".\".join(names)\n",
    "        print(f\"Processed qualified name: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def tactic_name(self, items):\n",
    "        return self.qualified_name(items)\n",
    "    \n",
    "    def plain_args(self, items):\n",
    "        print(f\"Plain args items: {items}\")\n",
    "        args = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Token):\n",
    "                args.append(item.value)\n",
    "            elif isinstance(item, Tree):\n",
    "                if item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "                else:\n",
    "                    args.append(str(item.children[0]))\n",
    "            else:\n",
    "                args.append(str(item))\n",
    "        print(f\"Processed plain args: {args}\")\n",
    "        return args\n",
    "    \n",
    "    def bracketed_names(self, items):\n",
    "        print(f\"Bracketed names items: {items}\")\n",
    "        names = []\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'qualified_name':\n",
    "                names.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, Token):\n",
    "                if item.type not in {'COMMA', 'LSQB', 'RSQB'}:\n",
    "                    names.append(item.value)\n",
    "            elif isinstance(item, str):\n",
    "                names.append(item)\n",
    "        print(f\"Processed bracketed names: {names}\")\n",
    "        return names\n",
    "    \n",
    "    def bracket_args(self, items):\n",
    "        print(f\"Bracket args items: {items}\")\n",
    "        for item in items:\n",
    "            if isinstance(item, Tree) and item.data == 'bracketed_names':\n",
    "                result = self.visit(item)\n",
    "                print(f\"Processed bracket args: {result}\")\n",
    "                return result\n",
    "            elif isinstance(item, list):\n",
    "                print(f\"Processed bracket args: {item}\")\n",
    "                return item\n",
    "        print(\"No valid bracket args found\")\n",
    "        return []\n",
    "    \n",
    "    def proof_body(self, items):\n",
    "        print(f\"Proof body items: {items}\")\n",
    "        tactics = []\n",
    "        for item in items:\n",
    "            if isinstance(item, LeanTactic):\n",
    "                tactics.append(item)\n",
    "            elif isinstance(item, Tree) and item.data == 'tactic':\n",
    "                tactics.append(self.visit(item))\n",
    "        print(f\"Processed proof body: {tactics}\")\n",
    "        return tactics\n",
    "    \n",
    "    def tactic(self, items):\n",
    "        print(f\"Tactic items: {items}\")\n",
    "        name = items[0]\n",
    "        args = []\n",
    "        for item in items[1:]:\n",
    "            if isinstance(item, Tree):\n",
    "                if item.data == 'bracket_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'plain_args':\n",
    "                    args.extend(self.visit(item))\n",
    "                elif item.data == 'qualified_name':\n",
    "                    args.append(self.qualified_name(item.children))\n",
    "            elif isinstance(item, list):\n",
    "                args.extend(item)\n",
    "            elif isinstance(item, Token) and item.type != '_NEWLINE':\n",
    "                args.append(item.value)\n",
    "        \n",
    "        tactic = LeanTactic(name=name, args=args if args else None)\n",
    "        print(f\"Created tactic: {tactic}\")\n",
    "        return tactic\n",
    "    \n",
    "    def proof(self, items):\n",
    "        print(f\"Proof items: {items}\")\n",
    "        for item in items:\n",
    "            if isinstance(item, list):\n",
    "                return item\n",
    "            elif isinstance(item, Tree) and item.data == 'proof_body':\n",
    "                return self.visit(item)\n",
    "        return []\n",
    "\n",
    "class LeanParser:\n",
    "    def __init__(self):\n",
    "        self.parser = Lark(lean_grammar, \n",
    "                          parser='lalr',\n",
    "                          transformer=LeanTransformer(),\n",
    "                          postlex=LeanIndenter(),\n",
    "                          debug=True)\n",
    "    \n",
    "    def find_theorems(self, code: str) -> List[str]:\n",
    "        \"\"\"Find all theorem blocks in the code.\"\"\"\n",
    "        theorems = []\n",
    "        lines = code.split('\\n')\n",
    "        current_theorem = []\n",
    "        in_theorem = False\n",
    "        indent_level = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('theorem '):\n",
    "                if in_theorem:\n",
    "                    # Save previous theorem if we find a new one\n",
    "                    theorems.append('\\n'.join(current_theorem))\n",
    "                    current_theorem = []\n",
    "                in_theorem = True\n",
    "                indent_level = len(line) - len(line.lstrip())\n",
    "                current_theorem.append(line)\n",
    "            elif in_theorem:\n",
    "                # Check if we're still in the theorem block\n",
    "                if line.strip() and len(line) - len(line.lstrip()) <= indent_level:\n",
    "                    in_theorem = False\n",
    "                    theorems.append('\\n'.join(current_theorem))\n",
    "                    current_theorem = []\n",
    "                else:\n",
    "                    current_theorem.append(line)\n",
    "        \n",
    "        # Don't forget the last theorem\n",
    "        if current_theorem:\n",
    "            theorems.append('\\n'.join(current_theorem))\n",
    "        \n",
    "        return theorems\n",
    "    \n",
    "    def parse_theorem(self, code: str) -> LeanTheorem:\n",
    "        try:\n",
    "            return self.parser.parse(code)\n",
    "        except Exception as e:\n",
    "            print(f\"Parse error: {type(e).__name__}: {str(e)}\")\n",
    "            raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
    "            \n",
    "    def parse_file(self, code: str) -> List[LeanTheorem]:\n",
    "        \"\"\"Parse all theorems in a file.\"\"\"\n",
    "        theorem_blocks = self.find_theorems(code)\n",
    "        theorems = []\n",
    "        \n",
    "        for block in theorem_blocks:\n",
    "            try:\n",
    "                theorem = self.parse_theorem(block)\n",
    "                theorems.append(theorem)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse theorem:\\n{block}\\nError: {e}\")\n",
    "        \n",
    "        return theorems\n",
    "\n",
    "# Test\n",
    "parser = LeanParser()\n",
    "test_input = \"\"\"\n",
    "theorem first (n : Nat) : n + 0 = n := by\n",
    "    rfl\n",
    "    simp\n",
    "\n",
    "theorem second (p q r : Prop)(a b c : Nat) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    simp\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    theorems = parser.parse_file(test_input)\n",
    "    print(f\"\\nParsing successful! Found {len(theorems)} theorems:\")\n",
    "    for theorem in theorems:\n",
    "        print(f\"\\nTheorem: {theorem.name}\")\n",
    "        print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in theorem.params]}\")\n",
    "        print(f\"Type: {theorem.type}\")\n",
    "        print(\"Proof tactics:\")\n",
    "        for tactic in theorem.proof:\n",
    "            print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 96,
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
   "id": "129f013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name list items: [Token('NAME', 'p'), Token('NAME', 'q'), Token('NAME', 'r')]\n",
      "Processed name list: ['p', 'q', 'r']\n",
      "Type items: [Token('NAME', 'Prop')]\n",
      "Param items: [['p', 'q', 'r'], LeanType(name='Prop', params=None)]\n",
      "Created param: LeanParam(name='p', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='q', type=LeanType(name='Prop', params=None))\n",
      "Created param: LeanParam(name='r', type=LeanType(name='Prop', params=None))\n",
      "Param list items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Processed param list: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]\n",
      "Params items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Param groups items: [[LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]]\n",
      "Processed param groups: [LeanParam(name='p', type=LeanType(name='Prop', params=None)), LeanParam(name='q', type=LeanType(name='Prop', params=None)), LeanParam(name='r', type=LeanType(name='Prop', params=None))]\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'q')]\n",
      "Processed qualified name: q\n",
      "Qualified name items: [Token('NAME', 'p')]\n",
      "Processed qualified name: p\n",
      "Qualified name items: [Token('NAME', 'r')]\n",
      "Processed qualified name: r\n",
      "Parse error: UnexpectedToken: Unexpected token Token('_NEWLINE', '\\n  ') at line 1, column 68.\n",
      "Expected one of: \n",
      "\t* BY\n",
      "\n",
      "Error: Failed to parse Lean code: Unexpected token Token('_NEWLINE', '\\n  ') at line 1, column 68.\n",
      "Expected one of: \n",
      "\t* BY\n",
      "\n",
      "Name list items: [Token('NAME', 'n')]\n",
      "Processed name list: ['n']\n",
      "Type items: [Token('NAME', 'Nat')]\n",
      "Param items: [['n'], LeanType(name='Nat', params=None)]\n",
      "Created param: LeanParam(name='n', type=LeanType(name='Nat', params=None))\n",
      "Param list items: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Processed param list: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Params items: [[LeanParam(name='n', type=LeanType(name='Nat', params=None))]]\n",
      "Param groups items: [[LeanParam(name='n', type=LeanType(name='Nat', params=None))]]\n",
      "Processed param groups: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'n')]\n",
      "Processed qualified name: n\n",
      "Qualified name items: [Token('NAME', 'rfl')]\n",
      "Processed qualified name: rfl\n",
      "Qualified name items: ['rfl']\n",
      "Processed qualified name: rfl\n",
      "Tactic items: ['rfl']\n",
      "Created tactic: LeanTactic(name='rfl', args=None)\n",
      "Qualified name items: [Token('NAME', 'repeat')]\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: ['repeat']\n",
      "Processed qualified name: repeat\n",
      "Qualified name items: [Token('NAME', 'try')]\n",
      "Processed qualified name: try\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Plain args items: ['try', 'simp']\n",
      "Processed plain args: ['try', 'simp']\n",
      "Tactic items: ['repeat', ['try', 'simp']]\n",
      "Created tactic: LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "Qualified name items: [Token('NAME', 'apply')]\n",
      "Processed qualified name: apply\n",
      "Qualified name items: ['apply']\n",
      "Processed qualified name: apply\n",
      "Qualified name items: [Token('NAME', 'nat.zero_add')]\n",
      "Processed qualified name: nat.zero_add\n",
      "Plain args items: ['nat.zero_add']\n",
      "Processed plain args: ['nat.zero_add']\n",
      "Tactic items: ['apply', ['nat.zero_add']]\n",
      "Created tactic: LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'add_comm')]\n",
      "Processed qualified name: add_comm\n",
      "Bracketed names items: ['add_comm']\n",
      "Processed bracketed names: ['add_comm']\n",
      "Bracket args items: [['add_comm']]\n",
      "Processed bracket args: ['add_comm']\n",
      "Tactic items: ['rw', ['add_comm']]\n",
      "Created tactic: LeanTactic(name='rw', args=['add_comm'])\n",
      "Qualified name items: [Token('NAME', 'rw')]\n",
      "Processed qualified name: rw\n",
      "Qualified name items: ['rw']\n",
      "Processed qualified name: rw\n",
      "Qualified name items: [Token('NAME', 'taylorWithinEval_succ')]\n",
      "Processed qualified name: taylorWithinEval_succ\n",
      "Qualified name items: [Token('NAME', 'Finset.sum_range_succ')]\n",
      "Processed qualified name: Finset.sum_range_succ\n",
      "Qualified name items: [Token('NAME', 'hk')]\n",
      "Processed qualified name: hk\n",
      "Bracketed names items: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Processed bracketed names: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Bracket args items: [['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Processed bracket args: ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']\n",
      "Tactic items: ['rw', ['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']]\n",
      "Created tactic: LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk'])\n",
      "Qualified name items: [Token('NAME', 'simp')]\n",
      "Processed qualified name: simp\n",
      "Qualified name items: ['simp']\n",
      "Processed qualified name: simp\n",
      "Tactic items: ['simp']\n",
      "Created tactic: LeanTactic(name='simp', args=None)\n",
<<<<<<< HEAD
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='repeat', args=['try', 'simp']), Token('_NEWLINE', '\\n    '), LeanTactic(name='apply', args=['nat.zero_add']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['add_comm']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None), Token('_NEWLINE', '\\n    ')]\n",
=======
      "Proof body items: [LeanTactic(name='rfl', args=None), Token('_NEWLINE', '\\n    '), LeanTactic(name='repeat', args=['try', 'simp']), Token('_NEWLINE', '\\n    '), LeanTactic(name='apply', args=['nat.zero_add']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['add_comm']), Token('_NEWLINE', '\\n    '), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), Token('_NEWLINE', '\\n    '), LeanTactic(name='simp', args=None)]\n",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
      "Processed proof body: [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]\n",
      "Proof items: [[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Theorem items: [Token('NAME', 'add_zero'), [LeanParam(name='n', type=LeanType(name='Nat', params=None))], 'n + 0 = n', [LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)]]\n",
      "Created theorem object: LeanTheorem(name='add_zero', params=[LeanParam(name='n', type=LeanType(name='Nat', params=None))], type='n + 0 = n', proof=[LeanTactic(name='rfl', args=None), LeanTactic(name='repeat', args=['try', 'simp']), LeanTactic(name='apply', args=['nat.zero_add']), LeanTactic(name='rw', args=['add_comm']), LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk']), LeanTactic(name='simp', args=None)])\n",
      "Name: add_zero\n",
      "Parameters: [LeanParam(name='n', type=LeanType(name='Nat', params=None))]\n",
      "Type: n + 0 = n\n",
      "Tactics:\n",
      "  - LeanTactic(name='rfl', args=None)\n",
      "  - LeanTactic(name='repeat', args=['try', 'simp'])\n",
      "  - LeanTactic(name='apply', args=['nat.zero_add'])\n",
      "  - LeanTactic(name='rw', args=['add_comm'])\n",
      "  - LeanTactic(name='rw', args=['taylorWithinEval_succ', 'Finset.sum_range_succ', 'hk'])\n",
      "  - LeanTactic(name='simp', args=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
<<<<<<< HEAD
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser_state.py\", line 77, in feed_token\n",
=======
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser_state.py\", line 77, in feed_token\n",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
      "    action, arg = states[state][token.type]\n",
      "                  ~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: '_NEWLINE'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
<<<<<<< HEAD
      "  File \"/tmp/ipykernel_17777/4108843905.py\", line 313, in parse_theorem\n",
      "    return self.parser.parse(code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/lark.py\", line 655, in parse\n",
      "    return self.parser.parse(text, start=start, on_error=on_error)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parser_frontends.py\", line 104, in parse\n",
      "    return self.parser.parse(stream, chosen_start, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser.py\", line 42, in parse\n",
      "    return self.parser.parse(lexer, start)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser.py\", line 88, in parse\n",
      "    return self.parse_from_state(parser_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser.py\", line 111, in parse_from_state\n",
      "    raise e\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser.py\", line 102, in parse_from_state\n",
      "    state.feed_token(token)\n",
      "  File \"/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/lark/parsers/lalr_parser_state.py\", line 80, in feed_token\n",
=======
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\4027140431.py\", line 289, in parse_theorem\n",
      "    return self.parser.parse(code)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\lark.py\", line 655, in parse\n",
      "    return self.parser.parse(text, start=start, on_error=on_error)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parser_frontends.py\", line 104, in parse\n",
      "    return self.parser.parse(stream, chosen_start, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 42, in parse\n",
      "    return self.parser.parse(lexer, start)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 88, in parse\n",
      "    return self.parse_from_state(parser_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 111, in parse_from_state\n",
      "    raise e\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser.py\", line 102, in parse_from_state\n",
      "    state.feed_token(token)\n",
      "  File \"C:\\Users\\15061\\AppData\\Roaming\\Python\\Python312\\site-packages\\lark\\parsers\\lalr_parser_state.py\", line 80, in feed_token\n",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
      "    raise UnexpectedToken(token, expected, state=self, interactive_parser=None)\n",
      "lark.exceptions.UnexpectedToken: Unexpected token Token('_NEWLINE', '\\n  ') at line 1, column 68.\n",
      "Expected one of: \n",
      "\t* BY\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
<<<<<<< HEAD
      "  File \"/tmp/ipykernel_17777/2417759609.py\", line 27, in <module>\n",
      "    result = parser.parse_theorem(test_input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_17777/4108843905.py\", line 316, in parse_theorem\n",
=======
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\1800906374.py\", line 27, in <module>\n",
      "    result = parser.parse_theorem(test_input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\15061\\AppData\\Local\\Temp\\ipykernel_22508\\4027140431.py\", line 292, in parse_theorem\n",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
      "    raise ValueError(f\"Failed to parse Lean code: {str(e)}\")\n",
      "ValueError: Failed to parse Lean code: Unexpected token Token('_NEWLINE', '\\n  ') at line 1, column 68.\n",
      "Expected one of: \n",
      "\t* BY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the parser\n",
    "if __name__ == \"__main__\":\n",
    "    parser = LeanParser()\n",
    "\n",
    "    test_input = \"\"\"theorem th_name (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n",
    "  Iff.intro\n",
    "    (fun h : p ∧ (q ∨ r) =>\n",
    "      have hp : p := h.left\n",
    "      Or.elim (h.right)\n",
    "        (fun hq : q =>\n",
    "          show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n",
    "        (fun hr : r =>\n",
    "          show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n",
    "    (fun h : (p ∧ q) ∨ (p ∧ r) =>\n",
    "      Or.elim h\n",
    "        (fun hpq : p ∧ q =>\n",
    "          have hp : p := hpq.left\n",
    "          have hq : q := hpq.right\n",
    "          show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n",
    "        (fun hpr : p ∧ r =>\n",
    "          have hp : p := hpr.left\n",
    "          have hr : r := hpr.right\n",
    "          show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = parser.parse_theorem(test_input)\n",
    "    print(f\"\\nParsing successful!\")\n",
    "    print(f\"Name: {result.name}\")\n",
    "    print(f\"Parameters: {[f'{p.name}: {p.type.name}' for p in result.params]}\")\n",
    "    print(f\"Type: {result.type}\")\n",
    "    print(\"Proof tactics:\")\n",
    "    for tactic in result.proof:\n",
    "        print(f\"  - {tactic.name}\" + (f\" {' '.join(tactic.args)}\" if tactic.args else \"\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "    \n",
    "    # Example theorem\n",
    "theorem_code = \"\"\"theorem add_zero (n : Nat) : n + 0 = n := by \n",
    "    rfl\n",
    "    repeat try simp\n",
    "    apply nat.zero_add\n",
    "    rw [add_comm]\n",
    "    rw [taylorWithinEval_succ, Finset.sum_range_succ, hk]\n",
<<<<<<< HEAD
    "    simp\n",
    "    \"\"\"\n",
=======
    "    simp\"\"\"\n",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
    "    \n",
    "try:\n",
    "        theorem = parser.parse_theorem(theorem_code)\n",
    "        print(f\"Name: {theorem.name}\")\n",
    "        print(f\"Parameters: {theorem.params}\")\n",
    "        print(f\"Type: {theorem.type}\")\n",
    "        print(\"Tactics:\")\n",
    "        for tactic in theorem.proof:\n",
    "            print(f\"  - {tactic}\")\n",
    "except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "ml_311",
=======
   "display_name": "ml01",
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.11"
=======
   "version": "3.12.8"
>>>>>>> 9aeecd432e46b411c668454cd213b7c78b1abff5
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
